name: Sentinel

on:
  push:
    branches:
      - master
  pull_request:

jobs:
  install-checks:
    runs-on: ubuntu-latest
    steps:
      - name: Check Spark 3.1.1 availability
        run: |
          wget --spider http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz
  test-suite:
    needs: install-checks
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.6]
        spark-version: [3.1.1]
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install add-ons
      run: |
        sudo apt-get install axel
    - name: Install Spark 3.1.1
      run: |
        axel -n10 --quiet https://archive.apache.org/dist/spark/spark-${{ matrix.spark-version }}/spark-${{ matrix.spark-version }}-bin-hadoop3.2.tgz
        tar -xf spark-${{ matrix.spark-version }}-bin-hadoop3.2.tgz
        echo "SPARK_HOME=$PWD/spark-${{ matrix.spark-version }}-bin-hadoop3.2" >> $GITHUB_ENV
    - name: Set up env [2/2]
      run: |
        echo "SPARKLIB=${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.7-src.zip" >> $GITHUB_ENV
        echo "$HOME/.local/bin" >> $GITHUB_PATH
        echo "${SPARK_HOME}/bin:${SPARK_HOME}/sbin" >> $GITHUB_PATH
        echo "spark.yarn.jars=${SPARK_HOME}/jars/*.jar" > ${SPARK_HOME}/conf/spark-defaults.conf
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip setuptools wheel
        pip install -r requirements.txt
        echo "PYTHONPATH=${SPARKLIB}" >> $GITHUB_ENV
    - name: Run test suites
      run: |
        sudo chown -R 1000 $PWD
        source ./build_image.sh
